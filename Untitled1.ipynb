{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pokus\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import sys\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plotter\n",
    "from gensim import corpora, models, similarities, matutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Defines dictionary from the specified corpus.\n",
    "dictionary = corpora.Dictionary(\n",
    "    line.lower().split() for line in open('docword.bow.txt', 'rb')\n",
    ")\n",
    "\n",
    "# Holds token ids which appears only once.\n",
    "unique_ids = [\n",
    "    token_id for token_id, frequency in dictionary.dfs.items() if frequency == 1\n",
    "]\n",
    "\n",
    "# Filters out tokens which appears only once.\n",
    "dictionary.filter_tokens(unique_ids)\n",
    "\n",
    "# Filters out tokens which appears in more than no_above documents,\n",
    "# and keeps only the first keep_n tokens.\n",
    "dictionary.filter_extremes(no_above=5, keep_n=100000)\n",
    "\n",
    "# Compactifies.\n",
    "dictionary.compactify()\n",
    "\n",
    "\n",
    "class Corpus(object):\n",
    "    \"\"\" Represents corpus.\n",
    "    \"\"\"\n",
    "    def __iter__(self):\n",
    "        \"\"\" Iterates over the specified corpus as bag-of-words object.\n",
    "        \"\"\"\n",
    "        for line in open('docword.bow.txt', 'r'):\n",
    "            yield dictionary.doc2bow(line.lower().split())\n",
    "\n",
    "\n",
    "# Instanciates corpus.\n",
    "my_corpus = Corpus()\n",
    "# Generates corpus length vectors.\n",
    "corpus_length_vector = numpy.array(\n",
    "    [sum(frequency for _, frequency in document) for document in my_corpus]\n",
    ")\n",
    "\n",
    "def symmetric_kl_divergence(p, q):\n",
    "    \"\"\" Caluculates symmetric Kullback-Leibler divergence.\n",
    "    \"\"\"\n",
    "    return numpy.sum([stats.entropy(p, q), stats.entropy(q, p)])\n",
    "\n",
    "\n",
    "def arun_metric(corpus, dictionary, min_topics=1, max_topics=1, iteration=1):\n",
    "    \"\"\" Caluculates Arun et al metric..\n",
    "    \"\"\"\n",
    "    result = [];\n",
    "    for i in range(min_topics, max_topics, iteration):\n",
    "        # Instanciates LDA.\n",
    "        lda = models.ldamodel.LdaModel(\n",
    "            corpus=corpus,\n",
    "            id2word=dictionary,\n",
    "            num_topics=i\n",
    "        )\n",
    "        # Caluculates raw LDA matrix.\n",
    "        matrix = lda.expElogbeta\n",
    "        # Caluculates SVD for LDA matris.\n",
    "        U, document_word_vector, V = numpy.linalg.svd(matrix)\n",
    "        # Gets LDA topics.\n",
    "        lda_topics = lda[my_corpus]\n",
    "        # Caluculates document-topic matrix.\n",
    "        term_document_matrix = matutils.corpus2dense(\n",
    "            lda_topics, lda.num_topics\n",
    "        ).transpose()\n",
    "        document_topic_vector = corpus_length_vector.dot(term_document_matrix)\n",
    "        document_topic_vector = document_topic_matrix + 0.0001\n",
    "        document_topic_norm   = numpy.linalg.norm(corpus_length_vector)\n",
    "        document_topic_vector = document_topic_vector / document_topic_norm\n",
    "        result.append(symmetric_kl_divergence(\n",
    "            document_word_vector,\n",
    "            document_topic_vector\n",
    "        ))\n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (9267,) and (1,1) not aligned: 9267 (dim 0) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-97aecba7799f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_corpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_dictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Caluculates symmetric KL divergence.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mkl_divergence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marun_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_corpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_topics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# Plots KL divergence against number of topics.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplotter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkl_divergence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-9846f8e63c90>\u001b[0m in \u001b[0;36marun_metric\u001b[1;34m(corpus, dictionary, min_topics, max_topics, iteration)\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[0mlda_topics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         ).transpose()\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mdocument_topic_vector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorpus_length_vector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mterm_document_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[0mdocument_topic_vector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdocument_topic_matrix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.0001\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mdocument_topic_norm\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_length_vector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (9267,) and (1,1) not aligned: 9267 (dim 0) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "my_corpus = corpora.UciCorpus(\"docword.kek_test.txt\", \"vocab.kek_test.txt\")\n",
    "dictionary = my_corpus.create_dictionary()\n",
    "# Caluculates symmetric KL divergence.\n",
    "kl_divergence = arun_metric(my_corpus, dictionary, max_topics=10);\n",
    "# Plots KL divergence against number of topics.\n",
    "plotter.plot(kl_divergence)\n",
    "plotter.ylabel('Symmetric KL Divergence')\n",
    "plotter.xlabel('Number of Topics')\n",
    "plotter.savefig('kl_topics.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Anaconda3]",
   "language": "python",
   "name": "Python [Anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
